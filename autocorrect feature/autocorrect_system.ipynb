{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-Based Spelling Autocorrector\n",
    "\n",
    "This notebook implements a complete spelling autocorrection system using:\n",
    "- Text corpus analysis\n",
    "- Word frequency probabilities\n",
    "- Edit distance operations\n",
    "- Candidate filtering and ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(directory_path='/mnt/project'):\n",
    "    \"\"\"\n",
    "    Load all text files from the specified directory.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    \n",
    "    # Get all .txt files\n",
    "    file_pattern = os.path.join(directory_path, '*.txt')\n",
    "    files = glob.glob(file_pattern)\n",
    "    \n",
    "    print(f\"Found {len(files)} text files\")\n",
    "    \n",
    "    for filepath in files:\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                text += f.read() + \" \"\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filepath}: {e}\")\n",
    "    \n",
    "    print(f\"Total characters loaded: {len(text):,}\")\n",
    "    return text\n",
    "\n",
    "# Load the corpus\n",
    "corpus_text = load_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Convert to lowercase and extract alphabetic words.\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Extract words (alphabetic only)\n",
    "    words = re.findall(r'[a-z]+', text)\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Process the corpus\n",
    "words = preprocess_text(corpus_text)\n",
    "print(f\"Total words extracted: {len(words):,}\")\n",
    "print(f\"Sample words: {words[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Vocabulary and Calculate Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(words):\n",
    "    \"\"\"\n",
    "    Create word frequency counter and vocabulary set.\n",
    "    \"\"\"\n",
    "    word_counts = Counter(words)\n",
    "    vocabulary = set(words)\n",
    "    total_words = len(words)\n",
    "    \n",
    "    return word_counts, vocabulary, total_words\n",
    "\n",
    "# Build vocabulary\n",
    "word_counts, vocabulary, total_words = build_vocabulary(words)\n",
    "\n",
    "print(f\"Unique words in vocabulary: {len(vocabulary):,}\")\n",
    "print(f\"\\nTop 20 most common words:\")\n",
    "for word, count in word_counts.most_common(20):\n",
    "    print(f\"  {word}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probability(word, word_counts, total_words):\n",
    "    \"\"\"\n",
    "    Calculate probability of a word: P(word) = count(word) / total_words\n",
    "    \"\"\"\n",
    "    return word_counts.get(word, 0) / total_words\n",
    "\n",
    "# Test probability calculation\n",
    "test_words = ['the', 'and', 'computer', 'xyzabc']\n",
    "print(\"Word probabilities:\")\n",
    "for word in test_words:\n",
    "    prob = word_probability(word, word_counts, total_words)\n",
    "    print(f\"  P('{word}') = {prob:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edit Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletion_edits(word):\n",
    "    \"\"\"\n",
    "    Generate all possible words by deleting one character.\n",
    "    Example: 'test' -> ['est', 'tst', 'tet', 'tes']\n",
    "    \"\"\"\n",
    "    return [word[:i] + word[i+1:] for i in range(len(word))]\n",
    "\n",
    "def insertion_edits(word):\n",
    "    \"\"\"\n",
    "    Generate all possible words by inserting one character.\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    return [word[:i] + c + word[i:] for i in range(len(word) + 1) for c in letters]\n",
    "\n",
    "def substitution_edits(word):\n",
    "    \"\"\"\n",
    "    Generate all possible words by substituting one character.\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    return [word[:i] + c + word[i+1:] for i in range(len(word)) for c in letters if c != word[i]]\n",
    "\n",
    "def transposition_edits(word):\n",
    "    \"\"\"\n",
    "    Generate all possible words by swapping adjacent characters.\n",
    "    Example: 'test' -> ['etst', 'tset', 'tets']\n",
    "    \"\"\"\n",
    "    return [word[:i] + word[i+1] + word[i] + word[i+2:] for i in range(len(word) - 1)]\n",
    "\n",
    "# Test edit operations\n",
    "test_word = \"test\"\n",
    "print(f\"Edit operations on '{test_word}':\")\n",
    "print(f\"  Deletions (first 5): {deletion_edits(test_word)[:5]}\")\n",
    "print(f\"  Insertions (first 5): {insertion_edits(test_word)[:5]}\")\n",
    "print(f\"  Substitutions (first 5): {substitution_edits(test_word)[:5]}\")\n",
    "print(f\"  Transpositions: {transposition_edits(test_word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Edit-1 Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_candidates(word):\n",
    "    \"\"\"\n",
    "    Generate all possible edit-distance-1 candidates.\n",
    "    \"\"\"\n",
    "    candidates = set()\n",
    "    \n",
    "    candidates.update(deletion_edits(word))\n",
    "    candidates.update(insertion_edits(word))\n",
    "    candidates.update(substitution_edits(word))\n",
    "    candidates.update(transposition_edits(word))\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "# Test candidate generation\n",
    "test_word = \"speling\"\n",
    "candidates = edit_one_candidates(test_word)\n",
    "print(f\"Generated {len(candidates)} edit-1 candidates for '{test_word}'\")\n",
    "print(f\"Sample candidates: {list(candidates)[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Filter and Rank Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_candidates(candidates, vocabulary):\n",
    "    \"\"\"\n",
    "    Keep only candidates that exist in the vocabulary.\n",
    "    \"\"\"\n",
    "    return [word for word in candidates if word in vocabulary]\n",
    "\n",
    "def rank_candidates(candidates, word_counts, total_words):\n",
    "    \"\"\"\n",
    "    Rank candidates by probability and return the best one.\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    # Calculate probabilities and sort\n",
    "    candidates_with_prob = [(word, word_probability(word, word_counts, total_words)) \n",
    "                            for word in candidates]\n",
    "    candidates_with_prob.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return candidates_with_prob[0][0]\n",
    "\n",
    "# Test filtering and ranking\n",
    "test_word = \"speling\"\n",
    "all_candidates = edit_one_candidates(test_word)\n",
    "valid_candidates = filter_candidates(all_candidates, vocabulary)\n",
    "print(f\"Valid candidates for '{test_word}': {valid_candidates[:10]}\")\n",
    "\n",
    "best = rank_candidates(valid_candidates, word_counts, total_words)\n",
    "print(f\"Best correction: '{best}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Edit-2 Candidates (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_candidates(word):\n",
    "    \"\"\"\n",
    "    Generate edit-distance-2 candidates (edits of edits).\n",
    "    Warning: This can generate a very large set.\n",
    "    \"\"\"\n",
    "    edit1 = edit_one_candidates(word)\n",
    "    edit2 = set()\n",
    "    \n",
    "    for w in edit1:\n",
    "        edit2.update(edit_one_candidates(w))\n",
    "    \n",
    "    return edit2\n",
    "\n",
    "# Test (on a short word to avoid excessive computation)\n",
    "test_word = \"helo\"\n",
    "edit2 = edit_two_candidates(test_word)\n",
    "print(f\"Generated {len(edit2)} edit-2 candidates for '{test_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Complete Autocorrect Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrect(word, vocabulary, word_counts, total_words, use_edit2=True):\n",
    "    \"\"\"\n",
    "    Main autocorrect function.\n",
    "    \n",
    "    Args:\n",
    "        word: Input word to correct\n",
    "        vocabulary: Set of valid words\n",
    "        word_counts: Counter object with word frequencies\n",
    "        total_words: Total word count\n",
    "        use_edit2: Whether to use edit-distance-2 if edit-1 fails\n",
    "    \n",
    "    Returns:\n",
    "        Corrected word (or original if no correction found)\n",
    "    \"\"\"\n",
    "    # Preprocess input\n",
    "    word = word.lower().strip()\n",
    "    \n",
    "    # If word is already correct, return it\n",
    "    if word in vocabulary:\n",
    "        return word\n",
    "    \n",
    "    # Try edit-distance-1\n",
    "    candidates = edit_one_candidates(word)\n",
    "    valid_candidates = filter_candidates(candidates, vocabulary)\n",
    "    \n",
    "    if valid_candidates:\n",
    "        return rank_candidates(valid_candidates, word_counts, total_words)\n",
    "    \n",
    "    # Try edit-distance-2 if enabled\n",
    "    if use_edit2:\n",
    "        candidates_2 = edit_two_candidates(word)\n",
    "        valid_candidates_2 = filter_candidates(candidates_2, vocabulary)\n",
    "        \n",
    "        if valid_candidates_2:\n",
    "            return rank_candidates(valid_candidates_2, word_counts, total_words)\n",
    "    \n",
    "    # No correction found, return original\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Testing with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases: common misspellings\n",
    "test_cases = [\n",
    "    \"speling\",\n",
    "    \"korrect\",\n",
    "    \"computr\",\n",
    "    \"langauge\",\n",
    "    \"progam\",\n",
    "    \"recieve\",\n",
    "    \"teh\",\n",
    "    \"thier\",\n",
    "    \"occured\",\n",
    "    \"definately\",\n",
    "    \"seperate\",\n",
    "    \"goverment\",\n",
    "    \"fredom\",\n",
    "    \"consitution\",\n",
    "    \"amercan\"\n",
    "]\n",
    "\n",
    "print(\"Autocorrect Results:\")\n",
    "print(\"=\" * 50)\n",
    "for word in test_cases:\n",
    "    corrected = autocorrect(word, vocabulary, word_counts, total_words)\n",
    "    print(f\"{word:20} -> {corrected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with correctly spelled words (should return unchanged)\n",
    "correct_words = [\"government\", \"freedom\", \"constitution\", \"american\", \"spelling\"]\n",
    "\n",
    "print(\"\\nCorrectly Spelled Words (should remain unchanged):\")\n",
    "print(\"=\" * 50)\n",
    "for word in correct_words:\n",
    "    corrected = autocorrect(word, vocabulary, word_counts, total_words)\n",
    "    status = \"✓\" if word == corrected else \"✗\"\n",
    "    print(f\"{status} {word:20} -> {corrected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interactive User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrect_sentence(sentence, vocabulary, word_counts, total_words):\n",
    "    \"\"\"\n",
    "    Autocorrect all words in a sentence.\n",
    "    \"\"\"\n",
    "    words = re.findall(r'[a-zA-Z]+', sentence)\n",
    "    corrected_words = [autocorrect(word, vocabulary, word_counts, total_words) \n",
    "                       for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# Example usage\n",
    "test_sentences = [\n",
    "    \"Ths is a tst sentance.\",\n",
    "    \"The goverment maks importnt decisons.\",\n",
    "    \"Fredom and democrcy are importnt valus.\"\n",
    "]\n",
    "\n",
    "print(\"Sentence Autocorrection:\")\n",
    "print(\"=\" * 70)\n",
    "for sentence in test_sentences:\n",
    "    corrected = autocorrect_sentence(sentence, vocabulary, word_counts, total_words)\n",
    "    print(f\"Original:  {sentence}\")\n",
    "    print(f\"Corrected: {corrected}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive input cell\n",
    "# Run this cell and type your text below\n",
    "\n",
    "user_input = input(\"Enter a word or sentence to autocorrect: \")\n",
    "corrected = autocorrect_sentence(user_input, vocabulary, word_counts, total_words)\n",
    "\n",
    "print(f\"\\nOriginal:  {user_input}\")\n",
    "print(f\"Corrected: {corrected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correction(word, vocabulary, word_counts, total_words):\n",
    "    \"\"\"\n",
    "    Detailed analysis of the correction process.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalyzing: '{word}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if already correct\n",
    "    if word in vocabulary:\n",
    "        print(f\"'{word}' is already in vocabulary (correctly spelled)\")\n",
    "        return word\n",
    "    \n",
    "    # Generate and filter edit-1 candidates\n",
    "    edit1 = edit_one_candidates(word)\n",
    "    valid1 = filter_candidates(edit1, vocabulary)\n",
    "    print(f\"Edit-1 candidates: {len(edit1)} generated, {len(valid1)} valid\")\n",
    "    \n",
    "    if valid1:\n",
    "        # Show top 5 candidates with probabilities\n",
    "        candidates_prob = [(w, word_probability(w, word_counts, total_words)) \n",
    "                          for w in valid1]\n",
    "        candidates_prob.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"\\nTop candidates:\")\n",
    "        for w, p in candidates_prob[:5]:\n",
    "            print(f\"  {w:15} P={p:.8f}\")\n",
    "        \n",
    "        best = candidates_prob[0][0]\n",
    "        print(f\"\\nBest correction: '{best}'\")\n",
    "        return best\n",
    "    \n",
    "    print(\"No valid edit-1 candidates found.\")\n",
    "    return word\n",
    "\n",
    "# Analyze some examples\n",
    "analyze_correction(\"speling\", vocabulary, word_counts, total_words)\n",
    "analyze_correction(\"goverment\", vocabulary, word_counts, total_words)\n",
    "analyze_correction(\"teh\", vocabulary, word_counts, total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This autocorrect system:\n",
    "- Loads a text corpus and builds a vocabulary\n",
    "- Calculates word probabilities based on frequency\n",
    "- Generates correction candidates using edit operations\n",
    "- Filters candidates to valid words\n",
    "- Selects the most probable correction\n",
    "\n",
    "The system works well for common typos within 1-2 edits of the correct word."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
